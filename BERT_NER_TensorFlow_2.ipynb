{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_NER_TensorFlow_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPZp6lDFMXdDA3sHeDE4xAa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "67e46e87d66f4de3bd070d186a7e8b38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c7ffbbb6ce61493fa4c4cbc3abd48982",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cf03bae366574874b0ddb0ad386b44a2",
              "IPY_MODEL_ec1f2f53e1cc41f6aac2178787fb0a20"
            ]
          }
        },
        "c7ffbbb6ce61493fa4c4cbc3abd48982": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cf03bae366574874b0ddb0ad386b44a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c91816f62c204869ab56a2d9d6fcd2a6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_258ae31fde67463885ac8bba0370bd46"
          }
        },
        "ec1f2f53e1cc41f6aac2178787fb0a20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b36e213510a74b33886c499c0fe5ae13",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:01&lt;00:00, 192kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b5b54075895d4d57a03e2f06dc8ace37"
          }
        },
        "c91816f62c204869ab56a2d9d6fcd2a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "258ae31fde67463885ac8bba0370bd46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b36e213510a74b33886c499c0fe5ae13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b5b54075895d4d57a03e2f06dc8ace37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3fbad3cf129946e991171540392dcb96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_978f1f97ba2540ea82cfe62f31e6f9ba",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1563891cf2a74493bc991309d90bc40f",
              "IPY_MODEL_3cd7ea3e0f814b5eae7d0ee76adfe5b8"
            ]
          }
        },
        "978f1f97ba2540ea82cfe62f31e6f9ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1563891cf2a74493bc991309d90bc40f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_df48c27319684c96b8452912cec4122a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_82c15973adbe46ccb52df15879282662"
          }
        },
        "3cd7ea3e0f814b5eae7d0ee76adfe5b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_48a4d4b91c124bb3b248feb94cfbb884",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29.0/29.0 [00:00&lt;00:00, 77.8B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_28c70ae6f0cc4515b0270369e586cba5"
          }
        },
        "df48c27319684c96b8452912cec4122a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "82c15973adbe46ccb52df15879282662": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "48a4d4b91c124bb3b248feb94cfbb884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "28c70ae6f0cc4515b0270369e586cba5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ba34f97a3dee4af9b09e6a0a0bed1694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c9810fa3b839409a92920acb903164f4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_44d15978c30b43c8bb3959d5bf5d4429",
              "IPY_MODEL_cb446d0886654baa887123606b079de2"
            ]
          }
        },
        "c9810fa3b839409a92920acb903164f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44d15978c30b43c8bb3959d5bf5d4429": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d899c4dc9c34404db47a406280ca32ee",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435797,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435797,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8fd73a6fa0714b57b0a269bbb4133b44"
          }
        },
        "cb446d0886654baa887123606b079de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b4d81094975b4c3a86d8d754deca291f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436k/436k [00:00&lt;00:00, 3.48MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3d4b7b1beefb41a0bc5db56081bffa8c"
          }
        },
        "d899c4dc9c34404db47a406280ca32ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8fd73a6fa0714b57b0a269bbb4133b44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b4d81094975b4c3a86d8d754deca291f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3d4b7b1beefb41a0bc5db56081bffa8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "39b3d64fe49548fcb610018d5866d743": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d4734a0392a249adbd59b553b69cff69",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5206f14768944fcc8d0472767114be4a",
              "IPY_MODEL_14289ca257c74a5797a23d56f6f08aff"
            ]
          }
        },
        "d4734a0392a249adbd59b553b69cff69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5206f14768944fcc8d0472767114be4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3544e49429e34766a2a8fa9e8969f7bc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_613be3f449a345018d0392a69fbdba30"
          }
        },
        "14289ca257c74a5797a23d56f6f08aff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_96c7b1045a654227a435496f1d00d475",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 2.92kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9f3bc2edab3740898d7c93a6784156c1"
          }
        },
        "3544e49429e34766a2a8fa9e8969f7bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "613be3f449a345018d0392a69fbdba30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "96c7b1045a654227a435496f1d00d475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9f3bc2edab3740898d7c93a6784156c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c53df60a904a401bb6ef3b511304c1ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2ef78d9adbac47c5aaf37ff59805f70a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c1e6a835f1934fbbb20af0333486a2c6",
              "IPY_MODEL_deed3efbe7cf4c38907ad03a58b7c568"
            ]
          }
        },
        "2ef78d9adbac47c5aaf37ff59805f70a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c1e6a835f1934fbbb20af0333486a2c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e27a643b4a9a4e0aa2d156857b9a1035",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 526681800,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 526681800,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_72d406fe21994774aeadf3b1e079fa3e"
          }
        },
        "deed3efbe7cf4c38907ad03a58b7c568": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e4cc3d290e3d45d9b4d3f791de0a8a60",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 527M/527M [00:13&lt;00:00, 37.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ab4faf368e5b4a238e94a7310126f4b9"
          }
        },
        "e27a643b4a9a4e0aa2d156857b9a1035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "72d406fe21994774aeadf3b1e079fa3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4cc3d290e3d45d9b4d3f791de0a8a60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ab4faf368e5b4a238e94a7310126f4b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/camipower/BERT/blob/main/BERT_NER_TensorFlow_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiwwvpVTmNOM"
      },
      "source": [
        "### Install huggingface transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usUGWqsTmMXN",
        "outputId": "25d28d16-e23f-4ff0-e860-0afc0e3c92e1"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.3MB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 33.8MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 901kB 40.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: huggingface-hub, tokenizers, sacremoses, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5x0zOIJGPgRV"
      },
      "source": [
        "### Check GPU Availability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2pwI4ukPRGS",
        "outputId": "377ab8ea-c17a-4554-f598-f8aeefcf5422"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxZIigwnPwX_",
        "outputId": "0c991113-65ab-48b4-b25e-40db778283cd"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.version.VERSION)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Xhojw5IP7iK"
      },
      "source": [
        "### Install TensorFlow Model Garden"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeCw6gg7P_cl"
      },
      "source": [
        "#!git clone --depth 1 -b v2.5.0 https://github.com/tensorflow/models.git"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVoUix0NQa29"
      },
      "source": [
        "# install requirements to use tensorflow/models repository (restart runtime afterwards)\n",
        "#!pip install -Uqr models/official/requirements.txt"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGZuyD4yQ-G0"
      },
      "source": [
        "### Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uvLd6FFRAfm"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_hub as hub\n",
        "import sys, os\n",
        "#sys.path.append('models')\n",
        "#from official.nlp.data import classifier_data_lib\n",
        "#from official.nlp.bert import tokenization\n",
        "#from official.nlp import optimization\n",
        "\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "from transformers import BertTokenizer, TFBertModel, BertConfig\n",
        "#from transformers import BertTokenizerFast, TFBertModel, BertConfig\n",
        "\n",
        "max_len = 256\n",
        "configuration = BertConfig()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O50iTswDReEx",
        "outputId": "846f8406-77d3-458b-8cec-b6bdafaf4426"
      },
      "source": [
        "print(\"TF Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF Version:  2.5.0\n",
            "Eager mode:  True\n",
            "Hub version:  0.12.0\n",
            "GPU is NOT AVAILABLE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JivK_lkrmiuI"
      },
      "source": [
        "### Setup Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "67e46e87d66f4de3bd070d186a7e8b38",
            "c7ffbbb6ce61493fa4c4cbc3abd48982",
            "cf03bae366574874b0ddb0ad386b44a2",
            "ec1f2f53e1cc41f6aac2178787fb0a20",
            "c91816f62c204869ab56a2d9d6fcd2a6",
            "258ae31fde67463885ac8bba0370bd46",
            "b36e213510a74b33886c499c0fe5ae13",
            "b5b54075895d4d57a03e2f06dc8ace37",
            "3fbad3cf129946e991171540392dcb96",
            "978f1f97ba2540ea82cfe62f31e6f9ba",
            "1563891cf2a74493bc991309d90bc40f",
            "3cd7ea3e0f814b5eae7d0ee76adfe5b8",
            "df48c27319684c96b8452912cec4122a",
            "82c15973adbe46ccb52df15879282662",
            "48a4d4b91c124bb3b248feb94cfbb884",
            "28c70ae6f0cc4515b0270369e586cba5",
            "ba34f97a3dee4af9b09e6a0a0bed1694",
            "c9810fa3b839409a92920acb903164f4",
            "44d15978c30b43c8bb3959d5bf5d4429",
            "cb446d0886654baa887123606b079de2",
            "d899c4dc9c34404db47a406280ca32ee",
            "8fd73a6fa0714b57b0a269bbb4133b44",
            "b4d81094975b4c3a86d8d754deca291f",
            "3d4b7b1beefb41a0bc5db56081bffa8c"
          ]
        },
        "id": "euiYX_QGmexy",
        "outputId": "0ec20ac9-f467-4c7a-820e-bd0c4f8e760d"
      },
      "source": [
        "#tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "#tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "#tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')\n",
        "\n",
        "slow_tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "save_path = \"bert_base_cased\"\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "slow_tokenizer.save_pretrained(save_path)\n",
        "\n",
        "tokenizer = BertWordPieceTokenizer(save_path + \"/vocab.txt\", lowercase=False)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "67e46e87d66f4de3bd070d186a7e8b38",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3fbad3cf129946e991171540392dcb96",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_wâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba34f97a3dee4af9b09e6a0a0bed1694",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435797.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5o4piNqm2-o",
        "outputId": "473b5228-113e-4600-f92e-9c81e1449efb"
      },
      "source": [
        "#print(tokenizer.wordpiece_tokenizer.tokenize(\" \".join(sentences[0])))\n",
        "#print(tokenizer.convert_tokens_to_ids(tokenizer.wordpiece_tokenizer.tokenize(\" \".join(sentences[0]))))\n",
        "\n",
        "#print(tokenizer.tokenize(\"I live in Germany.\"))\n",
        "#print(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"I live in Germany.\")))\n",
        "\n",
        "#slow_tokenizer.convert_ids_to_tokens(16)\n",
        "\n",
        "## Encoding(num_tokens=17, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
        "print(tokenizer.encode(\"Alex lives with Abhishek in London and works for Microsoft.\").tokens)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'Alex', 'lives', 'with', 'A', '##b', '##his', '##he', '##k', 'in', 'London', 'and', 'works', 'for', 'Microsoft', '.', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPmEOc67Vvet",
        "outputId": "91c8de54-15d3-45b3-a718-8c38428d685d"
      },
      "source": [
        "!git clone https://github.com/camipower/BERT_NER_1.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'BERT_NER_1'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 21 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (21/21), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FW4MbfXTWcOn"
      },
      "source": [
        "data_csv = \"BERT_NER_1/data/ner_dataset.csv\""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YP9dS680Z-q3"
      },
      "source": [
        "#print(df['Tag'].unique())\n",
        "#print()\n",
        "#print(df['Tag'].value_counts())"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciQTcfhm7tYI"
      },
      "source": [
        "# Set a dictionary for mapping tag name to id\n",
        "# tag2idx = {t: i for i, t in enumerate(tags_vals)}\n",
        "\n",
        "# Recommend to set it by manual define, good for reusing\n",
        "\n",
        "tag2idx = {'O': 0,\n",
        "           'X': 1,\n",
        "           'B-art': 2,\n",
        "           'I-art': 3,\n",
        "           'B-eve': 4,\n",
        "           'I-eve': 5,\n",
        "           'B-geo': 6,\n",
        "           'I-geo': 7,\n",
        "           'B-gpe': 8,\n",
        "           'I-gpe': 9,\n",
        "           'B-nat': 10,\n",
        "           'I-nat': 11,\n",
        "           'B-org': 12,\n",
        "           'I-org': 13,\n",
        "           'B-per': 14,\n",
        "           'I-per': 15,\n",
        "           'B-tim': 16,\n",
        "           'I-tim': 17,\n",
        "           '[CLS]': 18,\n",
        "           '[SEP]': 19}\n",
        "\n",
        "# Map also id to \n",
        "\n",
        "idx2tag = {tag2idx[key]: key for key in tag2idx}\n",
        "\n",
        "#print(tag2idx)\n",
        "#print(idx2tag)\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye7NYVtwP-YM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izgG6CbBSW1D"
      },
      "source": [
        "### Pre-process dataset and split into train/test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfBq-OQ_P-lS"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def process_csv(data_csv):\n",
        "    df = pd.read_csv(data_csv, sep=',', encoding='latin1')\n",
        "    df.loc[:, 'Sentence #'] = df['Sentence #'].fillna(method='ffill')\n",
        "    df['Sentence #'] = df['Sentence #'].apply(lambda x: re.sub(r\"Sentence: \", \"\", x))\n",
        "    df['Tag_id'] = df['Tag'].apply(lambda x: tag2idx[x])\n",
        "\n",
        "    sentences = df.groupby(\"Sentence #\")[\"Word\"].apply(list).values\n",
        "    tags = df.groupby(\"Sentence #\")[\"Tag_id\"].apply(list).values\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(sentences, tags, train_size=0.9, random_state=42)\n",
        "\n",
        "    #return sentences, tags    # , pos\n",
        "    return X_train, X_test, y_train, y_test    # , pos\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = process_csv(data_csv)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fvdztQPPJui"
      },
      "source": [
        "#import random\n",
        "#from sklearn.model_selection import GroupShuffleSplit\n",
        "#df['Tag_id'] = df['Tag'].apply(lambda x: tag2idx[x])\n",
        "#\n",
        "#\n",
        "#\n",
        "##train = df[df['Sentence #'].astype(int).isin(train_idx)]\n",
        "#\n",
        "#\n",
        "#\n",
        "##ids = df['Sentence #'].astype(int).unique()\n",
        "#np.random.seed(42)\n",
        "##np.random.shuffle(ids)\n",
        "##shuffled_df = df.set_index(\"Sentence #\").iloc[ids].reset_index()\n",
        "#\n",
        "#groups = [df for _, df in df.groupby('Sentence #')]\n",
        "#random.shuffle(groups)\n",
        "#shuffled_df = pd.concat(groups).reset_index(drop=True)\n",
        "#\n",
        "#train_inds, test_inds = next(GroupShuffleSplit(test_size=.10, n_splits=2, random_state=42).split(shuffled_df, groups=shuffled_df['Sentence #']))\n",
        "#train_df = shuffled_df.iloc[train_inds]\n",
        "#test_df = shuffled_df.iloc[test_inds]\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwLpHcBuW9JZ"
      },
      "source": [
        "#train.head(10)\n",
        "#train[train['Sentence #'] == \"4799\"]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sK2OjGgCVl_Z"
      },
      "source": [
        "#print(train.shape)\n",
        "#print(test.shape)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_xjAi6UJzhD"
      },
      "source": [
        "### Create tf.data.Datasets for Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYkAkQAzJxoe"
      },
      "source": [
        "#with tf.device('/cpu:0'):\n",
        "#    train_data = tf.data.Dataset.from_tensor_slices((train_df['Word'].values, train_df['Tag_id'].values))\n",
        "#    valid_data = tf.data.Dataset.from_tensor_slices((test_df['Word'].values, test_df['Tag_id'].values))\n",
        "#\n",
        "#    for text, label in train_data.take(1):\n",
        "#        print(text)\n",
        "#        print(label)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yCzy5fU-iF8"
      },
      "source": [
        "### Create input targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAgguM2G-hgY"
      },
      "source": [
        "def create_inputs_targets(sentences, tags):\n",
        "    \n",
        "    dataset_dict = {\n",
        "        'input_ids': [],\n",
        "        'token_type_ids': [],\n",
        "        'attention_mask': [],\n",
        "        'tags': []\n",
        "    }\n",
        "\n",
        "    for sentence, tag in zip(sentences, tags):\n",
        "        input_ids = []\n",
        "        target_tags = []\n",
        "        for i, word in enumerate(sentence):\n",
        "            ids = tokenizer.encode(word, add_special_tokens=False)\n",
        "            input_ids.extend(ids.ids)\n",
        "            \n",
        "            ## this is   a    differentiator -> ['this', 'is', 'a', 'different', '##ia', '##tor']\n",
        "            ## tag1 tag2 tag3 tag4           -> [tag1,   tag2, tag3, tag4,       tag4,   tag4]\n",
        "            num_tokens = len(ids)\n",
        "            target_tags.extend([tag[i]] * num_tokens)\n",
        "            #target_pos.extend([pos[i]] * num_tokens)   # if we want pos too (more needs to be done)\n",
        "        \n",
        "        # Pad truncate\n",
        "        # - 2 because 2 special tokens need to be added ([CLS], [SEP])\n",
        "        input_ids = input_ids[:max_len - 2]\n",
        "        target_tags = target_tags[:max_len - 2]\n",
        "\n",
        "        input_ids = [101] + input_ids + [102]   # Add special tokens ([CLS] -> 101, [SEP] -> 102)\n",
        "        #target_tags = [16] + target_tags + [16]\n",
        "        target_tags = [0] + target_tags + [0]\n",
        "        token_type_ids = [0] * len(input_ids)\n",
        "        attention_mask = [1] * len(input_ids)\n",
        "        padding_len = max_len - len(input_ids)\n",
        "\n",
        "        input_ids = input_ids + ([0] * padding_len)\n",
        "        attention_mask = attention_mask + ([0] * padding_len)\n",
        "        token_type_ids = token_type_ids + ([0] * padding_len)\n",
        "        #target_tags = target_tags + ([17] * padding_len)\n",
        "        target_tags = target_tags + ([0] * padding_len)\n",
        "\n",
        "        dataset_dict['input_ids'].append(input_ids)\n",
        "        dataset_dict['token_type_ids'].append(token_type_ids)\n",
        "        dataset_dict['attention_mask'].append(attention_mask)\n",
        "        dataset_dict['tags'].append(target_tags)\n",
        "        assert len(target_tags) == max_len, f'{len(input_ids)}, {len(target_tags)}'\n",
        "\n",
        "    for key in dataset_dict:\n",
        "        dataset_dict[key] = np.array(dataset_dict[key])\n",
        "\n",
        "    x = [\n",
        "         dataset_dict['input_ids'],\n",
        "         dataset_dict['token_type_ids'],\n",
        "         dataset_dict['attention_mask']\n",
        "    ]\n",
        "\n",
        "    y = dataset_dict['tags']\n",
        "\n",
        "    return x, y     #, tag_encoder\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9C3lCxq9XE0"
      },
      "source": [
        "x, y = create_inputs_targets(X_train, y_train)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ec--8xGgnA83",
        "outputId": "2ae2b6a8-e185-472b-ccb8-3d7fe42a2272"
      },
      "source": [
        "print(tokenizer.decode(x[0][0]))\n",
        "print(tokenizer.encode(tokenizer.decode(x[0][0])).tokens)\n",
        "print(y[0])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Kremlin officials insisted that they are cracking down on corporate crime.\n",
            "['[CLS]', 'K', '##rem', '##lin', 'officials', 'insisted', 'that', 'they', 'are', 'cracking', 'down', 'on', 'corporate', 'crime', '.', '[SEP]']\n",
            "[ 0 12 12 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hsslus8yaD0"
      },
      "source": [
        "### Define model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjxS9EI8yZDJ"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=False, reduction=tf.keras.losses.Reduction.NONE\n",
        ")\n",
        "\n",
        "def masked_ce_loss(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 17))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)\n",
        "\n",
        "def create_model(num_tags):\n",
        "    # BERT encoder\n",
        "    encoder = TFBertModel.from_pretrained('bert-base-cased')\n",
        "\n",
        "    # NER model\n",
        "    input_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "    token_type_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "    attention_mask = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "    embedding = encoder(\n",
        "        input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask\n",
        "    )[0]\n",
        "    embedding = layers.Dropout(0.3)(embedding)\n",
        "    tag_logits = layers.Dense(num_tags + 1, activation='softmax')(embedding)\n",
        "\n",
        "    model = keras.Model(\n",
        "        inputs=[input_ids, token_type_ids, attention_mask],\n",
        "        outputs=[tag_logits],\n",
        "    )\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(lr=3e-5)\n",
        "    \n",
        "    model.compile(optimizer=optimizer, loss=masked_ce_loss, metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WufTRm6OEzej"
      },
      "source": [
        "### Create model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "39b3d64fe49548fcb610018d5866d743",
            "d4734a0392a249adbd59b553b69cff69",
            "5206f14768944fcc8d0472767114be4a",
            "14289ca257c74a5797a23d56f6f08aff",
            "3544e49429e34766a2a8fa9e8969f7bc",
            "613be3f449a345018d0392a69fbdba30",
            "96c7b1045a654227a435496f1d00d475",
            "9f3bc2edab3740898d7c93a6784156c1",
            "c53df60a904a401bb6ef3b511304c1ca",
            "2ef78d9adbac47c5aaf37ff59805f70a",
            "c1e6a835f1934fbbb20af0333486a2c6",
            "deed3efbe7cf4c38907ad03a58b7c568",
            "e27a643b4a9a4e0aa2d156857b9a1035",
            "72d406fe21994774aeadf3b1e079fa3e",
            "e4cc3d290e3d45d9b4d3f791de0a8a60",
            "ab4faf368e5b4a238e94a7310126f4b9"
          ]
        },
        "id": "GYmmDIvH2HH-",
        "outputId": "03299245-f337-42d8-9e26-8f6b4ce7b8e6"
      },
      "source": [
        "#num_tags = pd.read_csv(data_csv, encoding='latin1')['Tag'].unique()\n",
        "num_tags = len(tag2idx)\n",
        "\n",
        "use_tpu = None\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    use_tpu = True\n",
        "except:\n",
        "    use_tpu = False\n",
        "\n",
        "if use_tpu:\n",
        "    # Create distribution strategy\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "    # Create model\n",
        "    with strategy.scope():\n",
        "        model = create_model(num_tags)\n",
        "\n",
        "else:\n",
        "    model = create_model(num_tags)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.29.32.242:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.29.32.242:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39b3d64fe49548fcb610018d5866d743",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c53df60a904a401bb6ef3b511304c1ca",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=526681800.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fdb67657e50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fdb67657e50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fdb67657e50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fdb82f04dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fdb82f04dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7fdb82f04dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 108310272   input_1[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 256, 768)     0           tf_bert_model[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256, 21)      16149       dropout_37[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 108,326,421\n",
            "Trainable params: 108,326,421\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kroxfv3RImQL"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVaB4Olp2HKV",
        "outputId": "634a44a8-a57a-46f7-ab28-28459a932dc0"
      },
      "source": [
        "#x_train, y_train, tag_encoder = create_inputs_targets(data_csv)\n",
        "x, y = create_inputs_targets(X_train, y_train)\n",
        "\n",
        "BATCH_SIZE = 64 if use_tpu else 16\n",
        "\n",
        "model.fit(\n",
        "    x,\n",
        "    y,\n",
        "    epochs=3,\n",
        "    verbose=1,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_split=0.1\n",
        ")"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 256) dtype=int64>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 256) dtype=int64>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 256) dtype=int64>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None, 256) dtype=int64>]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 256) dtype=int64>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 256) dtype=int64>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 256) dtype=int64>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None, 256) dtype=int64>]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "607/607 [==============================] - ETA: 0s - loss: 0.0420 - accuracy: 0.9895"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 256) dtype=int64>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 256) dtype=int64>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 256) dtype=int64>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None, 256) dtype=int64>]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "607/607 [==============================] - 188s 174ms/step - loss: 0.0420 - accuracy: 0.9895 - val_loss: 0.0151 - val_accuracy: 0.9950\n",
            "Epoch 2/3\n",
            "607/607 [==============================] - 90s 148ms/step - loss: 0.0129 - accuracy: 0.9955 - val_loss: 0.0126 - val_accuracy: 0.9955\n",
            "Epoch 3/3\n",
            "607/607 [==============================] - 90s 149ms/step - loss: 0.0106 - accuracy: 0.9961 - val_loss: 0.0123 - val_accuracy: 0.9955\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdabdf88890>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIQJjWtvOUP9"
      },
      "source": [
        "### Tag entities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWU8Y0LA2HMQ"
      },
      "source": [
        "def create_test_input_from_text(texts):\n",
        "    dataset_dict = {\n",
        "        \"input_ids\": [],\n",
        "        \"token_type_ids\": [],\n",
        "        \"attention_mask\": []\n",
        "    }\n",
        "    for sentence in texts:\n",
        "        input_ids = []\n",
        "        for idx, word in enumerate(sentence.split()):\n",
        "            ids = tokenizer.encode(word, add_special_tokens=False)\n",
        "            input_ids.extend(ids.ids)\n",
        "            num_tokens = len(ids)\n",
        "            \n",
        "        # Pad and create attention masks.\n",
        "        # Skip if truncation is needed\n",
        "        input_ids = input_ids[:max_len - 2]\n",
        "\n",
        "        input_ids = [101] + input_ids + [102]\n",
        "        n_tokens = len(input_ids)\n",
        "        token_type_ids = [0] * len(input_ids)\n",
        "        attention_mask = [1] * len(input_ids)\n",
        "        padding_len = max_len - len(input_ids)\n",
        "\n",
        "        input_ids = input_ids + ([0] * padding_len)\n",
        "        attention_mask = attention_mask + ([0] * padding_len)\n",
        "        token_type_ids = token_type_ids + ([0] * padding_len)\n",
        "        \n",
        "        dataset_dict[\"input_ids\"].append(input_ids)\n",
        "        dataset_dict[\"token_type_ids\"].append(token_type_ids)\n",
        "        dataset_dict[\"attention_mask\"].append(attention_mask)\n",
        "        \n",
        "    for key in dataset_dict:\n",
        "        dataset_dict[key] = np.array(dataset_dict[key])\n",
        "\n",
        "    x = [\n",
        "        dataset_dict[\"input_ids\"],\n",
        "        dataset_dict[\"token_type_ids\"],\n",
        "        dataset_dict[\"attention_mask\"],\n",
        "    ]\n",
        "    return x, n_tokens\n",
        "\n",
        "\n",
        "\n",
        "def tag_named_entities(query):\n",
        "\n",
        "    x_test, n_tokens = create_test_input_from_text(query)\n",
        "\n",
        "    pred_test = model.predict(x_test)\n",
        "    pred_tags = np.argmax(pred_test,2)[0][1:n_tokens-1]  # ignore predictions of padding tokens\n",
        "\n",
        "    # create dictionary of tags and their indexes\n",
        "#    le_dict = dict(zip(tag_encoder.transform(tag_encoder.classes_), tag_encoder.classes_))\n",
        "#    predicted_tags = [le_dict.get(_, '[pad]') for _ in pred_tags]\n",
        "    predicted_tags = [idx2tag[i] for i in pred_tags]\n",
        "\n",
        "\n",
        "    ids = x_test[0][0][:n_tokens]\n",
        "\n",
        "    tokenizer_tokens = tokenizer.encode(tokenizer.decode(ids)).tokens\n",
        "\n",
        "    # for debugging\n",
        "    print(tokenizer_tokens)\n",
        "\n",
        "    new_tokens, new_labels = [], []\n",
        "    for token, label in zip(tokenizer_tokens[1:-1], predicted_tags):\n",
        "        if token.startswith('##'):\n",
        "            new_tokens[-1] = new_tokens[-1] + token[2:]\n",
        "        else:\n",
        "            new_tokens.append(token)\n",
        "            new_labels.append(label)\n",
        "    \n",
        "    for token, label in zip(new_tokens, new_labels):\n",
        "        print(\"{}\\t{}\".format(token, label))\n",
        "\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etl8XqGU2HOU",
        "outputId": "87fc482c-840f-4684-d462-2a7c399e7e51"
      },
      "source": [
        "tag_named_entities([\"Alex lives with Abhishek in London and works for Microsoft Corp.\"])\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'Alex', 'lives', 'with', 'A', '##b', '##his', '##he', '##k', 'in', 'London', 'and', 'works', 'for', 'Microsoft', 'Corp', '.', '[SEP]']\n",
            "Alex\tB-per\n",
            "lives\tO\n",
            "with\tO\n",
            "Abhishek\tB-org\n",
            "in\tO\n",
            "London\tB-geo\n",
            "and\tO\n",
            "works\tO\n",
            "for\tO\n",
            "Microsoft\tB-org\n",
            "Corp\tI-org\n",
            ".\tO\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x21AQcqgXylf",
        "outputId": "31b00e28-fbfd-48d8-c846-1861fe30b123"
      },
      "source": [
        "tag_named_entities([\"Alex lives with Abhishek in London and works for Ayfie.\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'Alex', 'lives', 'with', 'A', '##b', '##his', '##he', '##k', 'in', 'London', 'and', 'works', 'for', 'A', '##y', '##fie', '.', '[SEP]']\n",
            "Alex\tB-per\n",
            "lives\tO\n",
            "with\tO\n",
            "Abhishek\tB-per\n",
            "in\tO\n",
            "London\tB-geo\n",
            "and\tO\n",
            "works\tO\n",
            "for\tO\n",
            "Ayfie\tB-per\n",
            ".\tO\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0wJJI8lX7Fm",
        "outputId": "b10f5c67-32c0-4ba4-9e23-a209b1333ccc"
      },
      "source": [
        "tag_named_entities([\"Alex lives with Abhishek in London and works in Ayfie.\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'Alex', 'lives', 'with', 'A', '##b', '##his', '##he', '##k', 'in', 'London', 'and', 'works', 'in', 'A', '##y', '##fie', '.', '[SEP]']\n",
            "Alex\tB-per\n",
            "lives\tO\n",
            "with\tO\n",
            "Abhishek\tB-per\n",
            "in\tO\n",
            "London\tB-geo\n",
            "and\tO\n",
            "works\tO\n",
            "in\tO\n",
            "Ayfie\tB-geo\n",
            ".\tO\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aLUQr5kMRqs",
        "outputId": "1480355c-ba44-4ac0-a0ad-c9aa525ebf86"
      },
      "source": [
        "tag_named_entities([\"Alex lives with Abhishek in London and works for Ayfie Inc.\"])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'Alex', 'lives', 'with', 'A', '##b', '##his', '##he', '##k', 'in', 'London', 'and', 'works', 'for', 'A', '##y', '##fie', 'Inc', '.', '[SEP]']\n",
            "Alex\tB-per\n",
            "lives\tO\n",
            "with\tO\n",
            "Abhishek\tB-org\n",
            "in\tO\n",
            "London\tB-geo\n",
            "and\tO\n",
            "works\tO\n",
            "for\tO\n",
            "Ayfie\tB-org\n",
            "Inc\tI-org\n",
            ".\tI-org\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut97wlQ7QrmH",
        "outputId": "c6fb9fae-466d-4454-9301-0740f804b5bf"
      },
      "source": [
        "tag_named_entities([\"Alex lives with Abhishek in London and works at Microsoft's headquarters in England.\"])"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'Alex', 'lives', 'with', 'A', '##b', '##his', '##he', '##k', 'in', 'London', 'and', 'works', 'at', 'Microsoft', \"'\", 's', 'headquarters', 'in', 'England', '.', '[SEP]']\n",
            "Alex\tB-per\n",
            "lives\tO\n",
            "with\tO\n",
            "Abhishek\tB-org\n",
            "in\tO\n",
            "London\tB-geo\n",
            "and\tO\n",
            "works\tO\n",
            "at\tO\n",
            "Microsoft\tB-org\n",
            "'\tO\n",
            "s\tO\n",
            "headquarters\tO\n",
            "in\tO\n",
            "England\tB-geo\n",
            ".\tO\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1wnY8qyhB7n",
        "outputId": "de426726-7e41-4334-c929-ff151b82c937"
      },
      "source": [
        "tag_named_entities([\"Abhishek and Jana are a couple.\"])"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'A', '##b', '##his', '##he', '##k', 'and', 'Jana', 'are', 'a', 'couple', '.', '[SEP]']\n",
            "Abhishek\tB-per\n",
            "and\tO\n",
            "Jana\tB-per\n",
            "are\tO\n",
            "a\tO\n",
            "couple\tO\n",
            ".\tO\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjZalqjQQruY",
        "outputId": "7fef0865-e983-44d8-b24b-4a55ed87785b"
      },
      "source": [
        "print(tokenizer.encode(\"Alex lives with Abhishek in London and works for Microsoft.\").tokens)\n",
        "print(tokenizer.encode(\"Alex lives with Abhishek in London and works for Microsoft.\").ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'Alex', 'lives', 'with', 'A', '##b', '##his', '##he', '##k', 'in', 'London', 'and', 'works', 'for', 'Microsoft', '.', '[SEP]']\n",
            "[101, 3230, 2491, 1114, 138, 1830, 27516, 4638, 1377, 1107, 1498, 1105, 1759, 1111, 6998, 119, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsi7kEYXk_58"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00ktygFCk_8U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfesYaUhk__Z",
        "outputId": "d2f368ac-842e-427e-cfeb-f223f7a77372"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "def evaluate_model(X_test, y_test):\n",
        "\n",
        "    \n",
        "    x, y = create_inputs_targets(X_test, y_test)\n",
        "    \n",
        "    model.evaluate(x, y, verbose=1)\n",
        "    #pred_test = model.predict(x)\n",
        "    #pred_tags = np.argmax(pred_test,2)\n",
        "\n",
        "\n",
        "\n",
        "    #print(np.squeeze(pred_tags).shape)\n",
        "    #print(np.squeeze(y).shape)\n",
        "\n",
        "    #print(confusion_matrix(pred_tags, y))\n",
        "\n",
        "    #print(\"Precision\", precision_score(y, pred_tags))\n",
        "    #print(\"Recall\", recall_score(y, pred_tags))\n",
        "    #print(\"f1_score\", f1_score(y, pred_tags))\n",
        "\n",
        "    #m = tf.keras.metrics.Precision()\n",
        "    #m.update_state(y, pred_tags)\n",
        "    #print(m.result().numpy())\n",
        "\n",
        "\n",
        "#    result = []\n",
        "#    for i in range(len(y)):\n",
        "#        for sent_true, sent_pred in zip(y[i], pred_tags[i]):\n",
        "#            result.append(sent_true == sent_pred)\n",
        "#    print(result)\n",
        "\n",
        "\n",
        "evaluate_model(X_test, y_test)\n"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "150/150 [==============================] - 6s 34ms/step - loss: nan - accuracy: 0.9957\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}